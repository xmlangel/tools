#!/usr/bin/env python3
"""
OpenWebUI í…ìŠ¤íŠ¸ ë²ˆì—­ê¸°
í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ OpenWebUI APIë¥¼ í†µí•´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
ê¸´ í…ìŠ¤íŠ¸ë„ ë¬¸ë§¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì „ì²´ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤.
"""

import requests
import json
import os
import sys
import argparse
import time
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def read_file(file_path):
    """íŒŒì¼ì„ ì½ì–´ì„œ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        sys.exit(1)

def save_file(file_path, content):
    """ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… ë²ˆì—­ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {file_path}")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def split_text(text, chunk_size=2000):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë§¥ì´ ëŠê¸°ì§€ ì•Šë„ë¡ ë¬¸ë‹¨/ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    ë‹¨ìˆœíˆ ê¸€ììˆ˜ë¡œ ìë¥´ë©´ ë¬¸ì¥ì´ ì˜ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°œí–‰ë¬¸ìë‚˜ ë§ˆì¹¨í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìë¦…ë‹ˆë‹¤.
    """
    chunks = []
    current_chunk = ""
    
    # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¨¼ì € ë¶„ë¦¬
    paragraphs = text.split('\n')
    
    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) < chunk_size:
            current_chunk += paragraph + "\n"
        else:
            # í˜„ì¬ ì²­í¬ê°€ ê½‰ ì°¼ìœ¼ë©´ ì €ì¥í•˜ê³  ì´ˆê¸°í™”
            if current_chunk:
                chunks.append(current_chunk)
            
            # ë§Œì•½ í•œ ë¬¸ë‹¨ì´ chunk_sizeë³´ë‹¤ í¬ë‹¤ë©´ ê°•ì œë¡œ ë‚˜ëˆ” (ë“œë¬¸ ê²½ìš°)
            if len(paragraph) > chunk_size:
                # ì´ ë¶€ë¶„ì€ ë” ì •êµí•˜ê²Œ í•  ìˆ˜ ìˆì§€ë§Œ, ì¼ë‹¨ì€ ê·¸ëƒ¥ ë„£ìŒ
                chunks.append(paragraph + "\n")
                current_chunk = ""
            else:
                current_chunk = paragraph + "\n"
    
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

def translate_chunk(text, api_url, api_key, model):
    """OpenWebUI APIë¥¼ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ë²ˆì—­í•©ë‹ˆë‹¤."""
    
    # ì‹œë„í•´ë³¼ ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡
    base_url = api_url.rstrip('/')
    endpoints = [
        f"{base_url}/api/chat/completions",  # OpenWebUI í‘œì¤€
        f"{base_url}/v1/chat/completions",   # OpenAI í˜¸í™˜
        f"{base_url}/api/v1/chat/completions",
        f"{base_url}/chat/completions",
        f"{base_url}/api/chat"               # ì¼ë¶€ êµ¬ë²„ì „
    ]
    
    # ì‚¬ìš©ìê°€ ì´ë¯¸ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í–ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„
    if 'chat/completions' in api_url or api_url.endswith('/chat'):
        endpoints.insert(0, api_url)

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜. 
    ë¬¸ë§¥ì„ ê³ ë ¤í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•˜ê³ , ë²ˆì—­ëœ ê²°ê³¼ë§Œ ì¶œë ¥í•´. 
    ì„¤ëª…ì´ë‚˜ ì¡ë‹´ì€ í•˜ì§€ ë§ˆ.
    
    [í…ìŠ¤íŠ¸ ì‹œì‘]
    {text}
    [í…ìŠ¤íŠ¸ ë]
    """
    
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are a professional translator. Translate the following text into Korean naturally."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3
    }

    last_error = None
    
    for target_url in endpoints:
        try:
            # print(f"Trying: {target_url}") # ë””ë²„ê¹…ìš©
            response = requests.post(target_url, headers=headers, json=data, timeout=120)
            
            # 404ë‚˜ 405ëŠ” ê²½ë¡œ ë¬¸ì œì´ë¯€ë¡œ ë‹¤ìŒ ê²½ë¡œ ì‹œë„
            if response.status_code in [404, 405]:
                last_error = f"{response.status_code} {response.reason}"
                continue
                
            response.raise_for_status()
            
            result = response.json()
            
            # ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content'].strip()
            # /api/chat ì—”ë“œí¬ì¸íŠ¸ì˜ ê²½ìš° (Ollama ìŠ¤íƒ€ì¼)
            elif 'message' in result:
                return result['message']['content'].strip()
            else:
                print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹ ({target_url}): {result}")
                return text 
                
        except Exception as e:
            last_error = str(e)
            continue
            
    print(f"âŒ ëª¨ë“  API ê²½ë¡œ ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
    return f"[ë²ˆì—­ ì‹¤íŒ¨]\n{text}"

def main():
    print("=== OpenWebUI í…ìŠ¤íŠ¸ ë²ˆì—­ê¸° ===")
    
    # 1. ì„¤ì • ì…ë ¥ (ì¸ìê°€ ì—†ìœ¼ë©´ ëŒ€í™”í˜•)
    parser = argparse.ArgumentParser()
    parser.add_argument('file', nargs='?', help='ë²ˆì—­í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--url', help='OpenWebUI ì£¼ì†Œ')
    parser.add_argument('--key', help='API Key')
    parser.add_argument('--model', help='ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„')
    
    args = parser.parse_args()
    
    file_path = args.file
    
    # í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì¸ìì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    api_url = args.url or os.getenv('OPENWEBUI_URL')
    api_key = args.key or os.getenv('OPENWEBUI_API_KEY')
    model = args.model or os.getenv('OPENWEBUI_MODEL')
    
    # ëŒ€í™”í˜• ì…ë ¥ (ê°’ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
    if not file_path:
        while True:
            file_path = input("\në²ˆì—­í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if os.path.exists(file_path):
                break
            print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    if not api_url:
        api_url = input("OpenWebUI ì£¼ì†Œ (ê¸°ë³¸ê°’: http://localhost:3000): ").strip()
        if not api_url:
            api_url = "http://localhost:3000"
            
    if not api_key:
        api_key = input("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
    if not model:
        model = input("ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: llama3, gpt-4): ").strip()
        if not model:
            print("ëª¨ë¸ ì´ë¦„ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            sys.exit(1)
            
    print(f"\nâš™ï¸  ì„¤ì • í™•ì¸:")
    print(f"   - URL: {api_url}")
    print(f"   - Model: {model}")
    print(f"   - API Key: {'*' * 5}{api_key[-4:] if api_key and len(api_key) > 4 else '****'}")

    # 2. íŒŒì¼ ì½ê¸° ë° ë¶„í• 
    print(f"\nğŸ“– íŒŒì¼ ì½ëŠ” ì¤‘: {file_path}")
    original_text = read_file(file_path)
    
    chunks = split_text(original_text)
    print(f"âœ‚ï¸ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.")
    
    # 3. ìˆœì°¨ì  ë²ˆì—­
    translated_parts = []
    
    print("\nğŸš€ ë²ˆì—­ ì‹œì‘...")
    for i, chunk in enumerate(chunks):
        print(f"[{i+1}/{len(chunks)}] ë²ˆì—­ ì¤‘... ({len(chunk)}ì)")
        translated_text = translate_chunk(chunk, api_url, api_key, model)
        translated_parts.append(translated_text)
        # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì‚´ì§ ëŒ€ê¸°
        time.sleep(0.5)
        
    # 4. ê²°ê³¼ í•©ì¹˜ê¸° ë° ì €ì¥
    final_translation = "\n\n".join(translated_parts)
    
    output_path = os.path.splitext(file_path)[0] + "_translated.txt"
    save_file(output_path, final_translation)
    
    print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
